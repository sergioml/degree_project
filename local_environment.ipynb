{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente \"local\" de pruebas\n",
    "En este notebook se hará el desarrollo del ambiente local de pruebas, en el que se incluirán las funciones necesarias y poder hacer un script final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scripts.local_environment as local\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean/train_clean.csv')\n",
    "df_targets = pd.read_csv('data/clean/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df[df['fecha_dato'] == '2015-01-28']\n",
    "y_train = df_targets.loc[x_train.index]\n",
    "\n",
    "x_test = df[df['fecha_dato'] == '2015-02-28']\n",
    "y_test = df_targets.loc[x_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x_train.drop(['fecha_dato', 'fecha_alta'], axis=1).as_matrix()\n",
    "y = y_train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtst = x_test.drop(['fecha_dato', 'fecha_alta'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "rf = model(x, y, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = rf.predict_proba(x_test)\n",
    "preds = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516199, 24)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = pred_probs = np.array([pr.max(axis=1) for pr in probs]).T\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 108 ms, total: 15.8 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted, actual = processPredictions(probs, preds, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.91 s, sys: 236 ms, total: 10.1 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subm = processPredictions(probs, preds, x_train, x_test, y_train, y_test, env='submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 4 ms, total: 2.45 s\n",
      "Wall time: 2.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025412497922884664"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mapk(actual, predicted, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect score\n",
    "Se hace una prueba de validación con un score casi perfecto (como si hubiese *overfitting*). La prueba se realiza con los meses de Enero y Febrero de 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df[df['fecha_dato'] == '2015-01-28']\n",
    "y_train = df_targets.loc[x_train.index]\n",
    "\n",
    "x_test = df[df['fecha_dato'] == '2015-02-28']\n",
    "y_test = df_targets.loc[x_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x_train, y_train, model):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: Array\n",
    "        Datos de entrenamiento previamente procesados\n",
    "    y_train: Array\n",
    "        Targets de entrenamiento\n",
    "    model: Objeto (de sklearn)\n",
    "        Algoritmo para entrenar con los paramétros configurados\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: Objeto\n",
    "        Algortimo entrenado\n",
    "    \"\"\"\n",
    "    return model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePredsProbs(x_test, clf):\n",
    "    \"\"\"\n",
    "    Función para calcular las probabilidades de predicción y predicciones hechas por el modelo entrenado\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_test: Array\n",
    "        Datos de test\n",
    "    clf: Objeto\n",
    "        El modelo previamente entrenado\n",
    "        \n",
    "    Results\n",
    "    -------\n",
    "    probs: Array\n",
    "        Array de las probabilidades de predicción\n",
    "    preds: Array\n",
    "        Array de predicciones\n",
    "\n",
    "    \"\"\"\n",
    "    preds = clf.predict(x_test)\n",
    "    \n",
    "    probs = clf.predict_proba(x_test)\n",
    "    probs = np.array([pr.max(axis=1) for pr in probs]).T\n",
    "    \n",
    "    return probs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processPredictions(probs=None, preds=None, df_train=None, df_test=None,\n",
    "                       df_targets=None, y_test=None, env='local', path='results/submissions/'):\n",
    "    \"\"\"\n",
    "    Procesamiento de las predicciones hechas para generar el archivo de submission\n",
    "    o los datos necesarios para hacer una validación local\n",
    "    Parameters\n",
    "    ----------\n",
    "    probs: Array\n",
    "        Probabilidades de elegir un producto - Generado por el modelo\n",
    "    preds: Array\n",
    "        Predicciones hechas por el modelo entrenado\n",
    "    df_train: DataFrame\n",
    "        Datos de entrenamiento - último mes de entrenamiento\n",
    "    df_test: DataFrame\n",
    "        Datos de test si se va a hacer una validación local, por el contrario es None por default\n",
    "    df_targets: DataFrame\n",
    "        Targets - último mes de entrenamiento\n",
    "    y_test: DataFrame\n",
    "        Targets del mes de test, sólo si env es 'local'\n",
    "    env: str (optional)\n",
    "        Indica el tipo de ejecución que se quiere hacer\n",
    "            'local': regresa dos listas para hacer la validación local - Default\n",
    "            'submit': regresa un DataFrame con el archivo de submission csv (el archivo de submission se genera\n",
    "                    y se guarda en el equipo)\n",
    "    path: str (optional)\n",
    "        Dirección de la carpeta donde se va a guardar el archivo\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Si env es 'submit'\n",
    "        df_subm: DataFrame\n",
    "            DataFrame con el archivo de submission csv (el archivo de submission se genera y se guarda en el equipo)\n",
    "    Si env es 'local'\n",
    "        predicted: list\n",
    "            Una lista de listas de los productos que se predijeron\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    df_targets.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ncodpers_prev_month = df_train.loc[:, 'ncodpers'].values\n",
    "    ncodpers_last_month = df_test.loc[:, 'ncodpers'].values\n",
    "    \n",
    "    ncodpers_both = list(set(ncodpers_last_month) & set(ncodpers_prev_month))\n",
    "    \n",
    "    index_prev = df_train[df_train['ncodpers'].isin(ncodpers_both)].sort_values(['ncodpers']).index\n",
    "    index_last = df_test[df_test['ncodpers'].isin(ncodpers_both)].sort_values(['ncodpers']).index\n",
    "    \n",
    "    prev_prods = df_targets.loc[index_prev].as_matrix()\n",
    "    pred_prods = preds[index_last, :]\n",
    "    \n",
    "    #Predicciones de los productos que están en ambos meses - Sólo productos añadidos\n",
    "    both_prods = pred_prods - prev_prods\n",
    "    both_prods = (both_prods > 0) * 1\n",
    "    \n",
    "    if env == 'submit':\n",
    "        \n",
    "        preds[index_last] = both_prods\n",
    "    \n",
    "        pred_probs = (preds * probs).argsort(axis=1)\n",
    "        pred_probs = np.fliplr(pred_probs)[:, :7]\n",
    "    \n",
    "        targets = np.array(df_targets.columns.tolist())\n",
    "        final_pred = [\" \".join(list(targets[p])) for p in pred_probs]\n",
    "\n",
    "        df_subm = pd.DataFrame({'ncodpers': df_test.ncodpers.values, 'added_products': final_pred})\n",
    "        name_file = path + time.strftime(\"%Y-%m-%d-h%H-%M-%S_\") + \"submission.csv\"\n",
    "        df_subm.to_csv(name_file, index=False)\n",
    "    \n",
    "        return df_subm\n",
    "    else:\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        y = y_test.loc[index_last].as_matrix()\n",
    "        purchases = y - prev_prods\n",
    "        purchases = (purchases > 0) * 1        \n",
    "        \n",
    "        indexs = np.array([[i for i in range(y.shape[1])] * y.shape[0]]).reshape(y.shape)\n",
    "        actual = purchases * indexs\n",
    "        actual = list(map(lambda x: list(np.unique(x)[1:]), actual))\n",
    "        \n",
    "        preds = both_prods #Estas son las predicciones de los productos que se añaden \n",
    "        probs = probs[index_last]\n",
    "        \n",
    "        pred_probs = (preds * probs).argsort(axis=1)\n",
    "        pred_probs = np.fliplr(pred_probs)[:, :7]        \n",
    "        \n",
    "        predicted = pred_probs\n",
    "        \n",
    "        return predicted, actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = x_train.reset_index(drop=True)\n",
    "df_test = x_test.reset_index(drop=True)\n",
    "df_labels = y_train.reset_index(drop=True)\n",
    "y = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_perfect = np.zeros(y_test.shape)\n",
    "preds_perfect = np.zeros(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncodpers_prev_month = df_train.loc[:, 'ncodpers'].values\n",
    "ncodpers_last_month = df_test.loc[:, 'ncodpers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512673"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncodpers_both = list(set(ncodpers_last_month) & set(ncodpers_prev_month))\n",
    "    \n",
    "index_prev = df_train[df_train['ncodpers'].isin(ncodpers_both)].sort_values(['ncodpers']).index\n",
    "index_last = df_test[df_test['ncodpers'].isin(ncodpers_both)].sort_values(['ncodpers']).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_prods = df_labels.loc[index_prev].as_matrix()\n",
    "pred_prods = y.loc[index_last].as_matrix() #Estos son los productos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases = pred_prods - prev_prods\n",
    "purchases = (purchases > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_perfect[index_last] = purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512673, 24)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases_plus = purchases.sum(axis=1)\n",
    "purchases_plus = np.array(list(map(lambda x: 1/x if 1/x != np.inf else 0, purchases_plus)))\n",
    "purchases_plus = purchases_plus.reshape((purchases.shape[0], 1))\n",
    "purchases_plus = purchases_plus * purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_perfect[index_last] = purchases_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 428 ms, total: 15.7 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted, actual = processPredictions(probs_perfect, preds_perfect, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 s, sys: 4 ms, total: 2.49 s\n",
      "Wall time: 2.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.039543724752425034"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mapk(actual, predicted, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_prods = pred_prods - prev_prods\n",
    "both_prods = (both_prods < 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.as_matrix()[index_last] - prev_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18], [], [], [], [4], [], [], [], [4], []]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Métrica de desempeño\n",
    "Para hacer mediciones locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From github: @benhamner\n",
    "\"\"\"\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Anaconda",
   "language": "python",
   "name": "pyconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
